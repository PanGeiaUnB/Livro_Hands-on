{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import random\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Pendulum-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testar_gpu():\n",
    "    train_on_gpu = torch.cuda.is_available() #Observa se a GPU está disponivel\n",
    "    if train_on_gpu: #Se sim\n",
    "        device = torch.device('cuda') #Seleciona o device como GPU\n",
    "        print(\"Treinando na GPU\") #E manda a mensagem\n",
    "    else: #Se não\n",
    "        device = torch.device('cpu') #Seleciona o device como cpu\n",
    "        print(\"GPU indisponível, treinando na CPU\") #E avisa que a GPU não esta disponível\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando na GPU\n"
     ]
    }
   ],
   "source": [
    "device = testar_gpu()\n",
    "\n",
    "\n",
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = int(env.observation_space.shape[0])\n",
    "output_size = int(env.action_space.shape[0])\n",
    "max_action = float(env.action_space.high[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "    def __init__(self, input_size, outputs):\n",
    "        super(Actor, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, 32)\n",
    "        self.ln1 = nn.LayerNorm(32)\n",
    "\n",
    "        self.linear2 = nn.Linear(32, 64)\n",
    "        self.ln2 = nn.LayerNorm(64)\n",
    "\n",
    "        self.linear3 = nn.Linear(64, outputs)\n",
    "        #self.linear3.weight.data.mul_(10)\n",
    "        #self.linear3.bias.data.mul_(10)\n",
    "        \n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        out = nn.functional.relu(self.ln1(self.linear1(x)))\n",
    "        out = nn.functional.relu(self.ln2(self.linear2(out)))\n",
    "        out = max_action*self.tanh(self.linear3(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    def __init__(self, state_size, action_size, outputs):\n",
    "        super(Critic, self).__init__()\n",
    "        self.linear1 = nn.Linear(state_size, 32)\n",
    "        self.ln1 = nn.LayerNorm(32)\n",
    "\n",
    "        self.linear2 = nn.Linear(32 + action_size, 64)\n",
    "        self.ln2 = nn.LayerNorm(64)\n",
    "\n",
    "        self.linear3 = nn.Linear(64, outputs)\n",
    "        self.linear3.weight.data.mul_(10)\n",
    "        self.linear3.bias.data.mul_(10)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, state, action):\n",
    "        s1 = nn.functional.relu(self.ln1(self.linear1(state)))\n",
    "        out = torch.cat((s1,action), dim=1)\n",
    "        out = nn.functional.relu(self.ln2(self.linear2(out)))\n",
    "        out = self.linear3(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "GAMMA = 0.95\n",
    "tau = 0.05\n",
    "\n",
    "# CONFIG PARAM NOISE\n",
    "sigma_0 = 0.30\n",
    "alfa = 1.01\n",
    "delta = 1e-1\n",
    "T_adapt = 5\n",
    "\n",
    "#CONFIG ACNOISE\n",
    "desv_pad_ac = 0.3\n",
    "T_adapt_ac = 20\n",
    "alfa_ac = 1.01\n",
    "\n",
    "actor_net = Actor(input_size, output_size).to(device)\n",
    "actor_noise_net = Actor(input_size, output_size).to(device)\n",
    "actor_target_net = Actor(input_size, output_size).to(device)\n",
    "\n",
    "critic_net = Critic(input_size, output_size, 1).to(device)\n",
    "critic_target_net = Critic(input_size, output_size, 1).to(device)\n",
    "\n",
    "actor_target_net.load_state_dict(actor_net.state_dict())\n",
    "actor_target_net.eval()\n",
    "actor_noise_net.load_state_dict(actor_net.state_dict())\n",
    "actor_noise_net.eval()\n",
    "critic_target_net.load_state_dict(critic_net.state_dict())\n",
    "critic_target_net.eval()\n",
    "\n",
    "optimizer_critic = torch.optim.AdamW(critic_net.parameters(), lr=0.001)\n",
    "optimizer_actor = torch.optim.AdamW(actor_net.parameters(), lr=0.0002)\n",
    "\n",
    "memory = ReplayMemory(5000)\n",
    "\n",
    "loss_d = nn.MSELoss()\n",
    "loss_critic = nn.SmoothL1Loss()\n",
    "\n",
    "actor_loss = None\n",
    "critic_loss = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(state, action_noise=None, param_noise=None):\n",
    "    actor_net.eval()\n",
    "    if param_noise is not None: \n",
    "        mu = actor_noise_net(state.float())\n",
    "    else:\n",
    "        mu = actor_net(state.float())\n",
    "\n",
    "    mu = mu.data\n",
    "    if action_noise is not None:\n",
    "        with torch.no_grad():\n",
    "            mu = torch.Tensor(mu.cpu().numpy() + np.random.normal(0,desv_pad_ac,output_size)).to(device)\n",
    "\n",
    "    mu = mu.squeeze()\n",
    "    return mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weightSync(target_model, source_model):\n",
    "    for parameter_target, parameter_source in zip(target_model.parameters(), source_model.parameters()):\n",
    "        parameter_target.data.copy_((1 - tau) * parameter_target.data + tau * parameter_source.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model(t):\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    \n",
    "    actor_net.train()\n",
    "    critic_net.train()\n",
    "    actor_target_net.train()\n",
    "    critic_target_net.train()\n",
    "\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    action_batch, state_batch = [],[]\n",
    "    next_state_batch = torch.autograd.Variable(torch.cat(batch.next_state)).to(device)\n",
    "    state_batch = torch.cat(batch.state).to(device)\n",
    "    for tupla in batch.action:\n",
    "        action_batch.append(np.array(tupla.cpu()))\n",
    "    action_batch = torch.from_numpy(np.array(action_batch)).view(-1,1).to(device)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    next_actor_action_value = actor_target_net(next_state_batch.float())\n",
    "    with torch.no_grad():\n",
    "        next_state_values = critic_target_net(next_state_batch.float(), next_actor_action_value.float()).squeeze()\n",
    "\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer_critic.zero_grad()\n",
    "    state_action_values = critic_net(state_batch.float(), action_batch.float())\n",
    "    critic_loss = loss_critic(state_action_values.float(), expected_state_action_values.unsqueeze(1).float())\n",
    "    if i_episode == 10:\n",
    "        print(critic_loss)\n",
    "    if i_episode == 50:\n",
    "        print(critic_loss)\n",
    "        \n",
    "    \n",
    "    critic_loss.backward()\n",
    "    optimizer_critic.step()\n",
    "\n",
    "    optimizer_actor.zero_grad()            \n",
    "    gradient = -critic_net(state_batch.float(), actor_net(state_batch.float()).float())\n",
    "    actor_loss = torch.mean(gradient)\n",
    "    actor_loss.backward()\n",
    "    optimizer_actor.step()\n",
    "    \n",
    "    if t%10 == 0: \n",
    "        weightSync(actor_target_net, actor_net)\n",
    "        weightSync(critic_target_net, critic_net)\n",
    "    \n",
    "    return state_batch, action_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodio 0: retorno=27.12\n",
      "Episodio 1: retorno=45.36\n",
      "Episodio 2: retorno=12.15\n",
      "Episodio 3: retorno=85.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/augusto/anaconda3/lib/python3.8/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([100, 1])) that is different to the input size (torch.Size([100])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "D:  2.013395309448242    Sigma:  0.297029702970297\n",
      "Episodio 4: retorno=29.68\n",
      "Episodio 5: retorno=70.21\n",
      "Episodio 6: retorno=70.98\n",
      "Episodio 7: retorno=25.1\n",
      "Episodio 8: retorno=13.67\n",
      " \n",
      "D:  1.4419639110565186    Sigma:  0.29408881482207627\n",
      "Episodio 9: retorno=28.84\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0040, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0040, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0046, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0045, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0045, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0049, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0050, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0042, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0050, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0049, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0045, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0073, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0040, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0054, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0065, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0048, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0047, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0049, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0049, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0056, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0042, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0082, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0053, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0049, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0060, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0076, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0078, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0055, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0053, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0059, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0048, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0080, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0040, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0061, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0042, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0059, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0050, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0042, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0066, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0078, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0042, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0045, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0042, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0061, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0046, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0045, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0040, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0043, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0051, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0046, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0043, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0040, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0047, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0043, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0042, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0068, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0043, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0064, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0063, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0066, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0091, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0102, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0123, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0055, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0164, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0076, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0090, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0086, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0082, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0081, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0071, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0056, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0079, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0095, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0080, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0054, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0121, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0128, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0077, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0101, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0049, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0071, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0078, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0059, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0055, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0058, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0051, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0050, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0048, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0046, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "Episodio 10: retorno=23.41\n",
      "Episodio 11: retorno=29.24\n",
      "Episodio 12: retorno=58.64\n",
      "Episodio 13: retorno=79.49\n",
      " \n",
      "D:  1.4848703145980835    Sigma:  0.29117704437829334\n",
      "Episodio 14: retorno=19.93\n",
      "Episodio 15: retorno=69.93\n",
      "Episodio 16: retorno=32.55\n",
      "Episodio 17: retorno=65.54\n",
      "Episodio 18: retorno=65.13\n",
      " \n",
      "D:  1.2669566869735718    Sigma:  0.2882941033448449\n",
      "Episodio 19: retorno=84.13\n",
      "Episodio 20: retorno=79.77\n",
      "Episodio 21: retorno=80.6\n",
      "Episodio 22: retorno=88.77\n",
      "Episodio 23: retorno=13.69\n",
      " \n",
      "D:  1.332255482673645    Sigma:  0.28543970628202464\n",
      "Episodio 24: retorno=51.39\n",
      "Episodio 25: retorno=12.96\n",
      "Episodio 26: retorno=72.05\n",
      "Episodio 27: retorno=78.77\n",
      "Episodio 28: retorno=77.45\n",
      " \n",
      "D:  2.0122382640838623    Sigma:  0.282613570576262\n",
      "Episodio 29: retorno=20.72\n",
      "Episodio 30: retorno=50.09\n",
      "Episodio 31: retorno=79.38\n",
      "Episodio 32: retorno=80.88\n",
      "Episodio 33: retorno=28.52\n",
      " \n",
      "D:  1.7298340797424316    Sigma:  0.2798154164121406\n",
      "Episodio 34: retorno=79.62\n",
      "Episodio 35: retorno=80.68\n",
      "Episodio 36: retorno=31.81\n",
      "Episodio 37: retorno=25.42\n",
      "Episodio 38: retorno=82.57\n",
      " \n",
      "D:  1.7316007614135742    Sigma:  0.27704496674469364\n",
      "Episodio 39: retorno=77.67\n",
      "Episodio 40: retorno=90.25\n",
      "Episodio 41: retorno=81.31\n",
      "Episodio 42: retorno=65.63\n",
      "Episodio 43: retorno=23.96\n",
      " \n",
      "D:  1.6292952299118042    Sigma:  0.2743019472719739\n",
      "Episodio 44: retorno=7.03\n",
      "Episodio 45: retorno=74.99\n",
      "Episodio 46: retorno=89.81\n",
      "Episodio 47: retorno=44.73\n",
      "Episodio 48: retorno=28.98\n",
      " \n",
      "D:  1.7380880117416382    Sigma:  0.27158608640789494\n",
      "Episodio 49: retorno=49.04\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0053, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0046, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0059, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0047, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0050, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0053, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0045, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0050, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0058, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0051, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0056, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0050, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0048, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0043, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0051, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0049, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0046, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0049, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0056, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0055, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0047, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0045, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0048, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0040, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0049, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0046, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0047, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0047, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0042, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0043, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0052, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0042, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0048, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0056, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0040, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0042, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0043, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0049, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0043, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0045, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0049, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0049, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0053, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0050, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0040, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0042, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0047, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0065, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0050, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0043, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0040, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0043, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0045, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0040, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0050, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0040, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0046, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0047, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0047, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0056, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0049, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0064, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0056, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0053, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0059, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0056, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0043, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0049, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0066, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0058, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0054, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0043, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0040, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0051, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0040, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0066, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0046, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0040, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0048, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0043, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0045, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0040, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0043, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0040, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0061, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0048, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0040, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0046, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0043, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0043, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor(0.0050, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "Episodio 50: retorno=71.88\n",
      "Episodio 51: retorno=71.21\n",
      "Episodio 52: retorno=65.34\n",
      "Episodio 53: retorno=65.15\n",
      " \n",
      "D:  1.4116790294647217    Sigma:  0.26889711525534155\n",
      "Episodio 54: retorno=40.21\n",
      "Episodio 55: retorno=66.09\n",
      "Episodio 56: retorno=79.18\n",
      "Episodio 57: retorno=74.47\n",
      "Episodio 58: retorno=84.66\n",
      " \n",
      "D:  1.1629406213760376    Sigma:  0.26623476757954606\n",
      "Episodio 59: retorno=80.76\n",
      "Episodio 60: retorno=50.91\n",
      "Episodio 61: retorno=52.92\n",
      "Episodio 62: retorno=85.85\n",
      "Episodio 63: retorno=50.76\n",
      " \n",
      "D:  1.9644948244094849    Sigma:  0.2635987797817288\n",
      "Episodio 64: retorno=65.77\n",
      "Episodio 65: retorno=33.95\n",
      "Episodio 66: retorno=38.32\n",
      "Episodio 67: retorno=29.68\n",
      "Episodio 68: retorno=14.56\n",
      " \n",
      "D:  2.09971284866333    Sigma:  0.2609888908729988\n",
      "Episodio 69: retorno=89.28\n",
      "Episodio 70: retorno=21.41\n",
      "Episodio 71: retorno=82.35\n",
      "Episodio 72: retorno=8.42\n",
      "Episodio 73: retorno=33.1\n",
      " \n",
      "D:  1.264492392539978    Sigma:  0.2584048424485137\n",
      "Episodio 74: retorno=65.74\n",
      "Episodio 75: retorno=77.84\n",
      "Episodio 76: retorno=77.66\n",
      "Episodio 77: retorno=25.57\n",
      "Episodio 78: retorno=75.06\n",
      " \n",
      "D:  0.8694044947624207    Sigma:  0.25584637866189475\n",
      "Episodio 79: retorno=80.43\n",
      "Episodio 80: retorno=15.38\n",
      "Episodio 81: retorno=28.56\n",
      "Episodio 82: retorno=12.64\n",
      "Episodio 83: retorno=87.57\n",
      " \n",
      "D:  1.0774716138839722    Sigma:  0.2533132461998958\n",
      "Episodio 84: retorno=73.64\n",
      "Episodio 85: retorno=28.24\n",
      "Episodio 86: retorno=78.53\n",
      "Episodio 87: retorno=-10.82\n",
      "Episodio 88: retorno=83.51\n",
      " \n",
      "D:  1.434683084487915    Sigma:  0.25080519425732256\n",
      "Episodio 89: retorno=85.49\n",
      "Episodio 90: retorno=86.59\n",
      "Episodio 91: retorno=45.83\n",
      "Episodio 92: retorno=26.96\n",
      "Episodio 93: retorno=77.7\n",
      " \n",
      "D:  1.343996286392212    Sigma:  0.24832197451220056\n",
      "Episodio 94: retorno=19.54\n",
      "Episodio 95: retorno=30.37\n",
      "Episodio 96: retorno=38.62\n",
      "Episodio 97: retorno=50.48\n",
      "Episodio 98: retorno=73.39\n",
      " \n",
      "D:  0.7980720400810242    Sigma:  0.24586334110118868\n",
      "Episodio 99: retorno=78.43\n",
      "Episodio 100: retorno=-2.52\n",
      "Episodio 101: retorno=70.9\n",
      "Episodio 102: retorno=29.55\n",
      "Episodio 103: retorno=63.24\n",
      " \n",
      "D:  1.1263513565063477    Sigma:  0.2434290505952363\n",
      "Episodio 104: retorno=87.37\n",
      "Episodio 105: retorno=30.96\n",
      "Episodio 106: retorno=78.28\n",
      "Episodio 107: retorno=76.01\n",
      "Episodio 108: retorno=34.97\n",
      " \n",
      "D:  1.232987403869629    Sigma:  0.2410188619754815\n",
      "Episodio 109: retorno=76.86\n",
      "Episodio 110: retorno=67.92\n",
      "Episodio 111: retorno=28.3\n",
      "Episodio 112: retorno=-24.27\n",
      "Episodio 113: retorno=83.94\n",
      " \n",
      "D:  1.2232506275177002    Sigma:  0.23863253660938763\n",
      "Episodio 114: retorno=46.95\n",
      "Episodio 115: retorno=26.84\n",
      "Episodio 116: retorno=33.74\n",
      "Episodio 117: retorno=36.29\n",
      "Episodio 118: retorno=13.28\n",
      " \n",
      "D:  0.7754086256027222    Sigma:  0.23626983822711647\n",
      "Episodio 119: retorno=78.68\n",
      "Episodio 120: retorno=31.13\n",
      "Episodio 121: retorno=74.41\n",
      "Episodio 122: retorno=81.73\n",
      "Episodio 123: retorno=20.75\n",
      " \n",
      "D:  1.1035219430923462    Sigma:  0.23393053289813512\n",
      "Episodio 124: retorno=70.75\n",
      "Episodio 125: retorno=71.7\n",
      "Episodio 126: retorno=77.81\n",
      "Episodio 127: retorno=27.09\n",
      "Episodio 128: retorno=80.67\n",
      " \n",
      "D:  1.1190614700317383    Sigma:  0.23161438900805456\n",
      "Episodio 129: retorno=88.57\n",
      "Episodio 130: retorno=43.16\n",
      "Episodio 131: retorno=19.25\n",
      "Episodio 132: retorno=27.9\n",
      "Episodio 133: retorno=79.19\n",
      " \n",
      "D:  1.7983763217926025    Sigma:  0.2293211772356976\n",
      "Episodio 134: retorno=39.78\n",
      "Episodio 135: retorno=78.58\n",
      "Episodio 136: retorno=72.85\n",
      "Episodio 137: retorno=39.26\n",
      "Episodio 138: retorno=70.28\n",
      " \n",
      "D:  1.0113987922668457    Sigma:  0.22705067053039366\n",
      "Episodio 139: retorno=84.73\n",
      "Episodio 140: retorno=25.05\n",
      "Episodio 141: retorno=32.05\n",
      "Episodio 142: retorno=72.23\n",
      "Episodio 143: retorno=81.44\n",
      " \n",
      "D:  1.0797029733657837    Sigma:  0.22480264408949865\n",
      "Episodio 144: retorno=77.67\n",
      "Episodio 145: retorno=73.11\n",
      "Episodio 146: retorno=86.17\n",
      "Episodio 147: retorno=81.46\n",
      "Episodio 148: retorno=78.94\n",
      " \n",
      "D:  1.4099518060684204    Sigma:  0.2225768753361373\n",
      "Episodio 149: retorno=65.42\n",
      "Episodio 150: retorno=80.65\n",
      "Episodio 151: retorno=78.9\n",
      "Episodio 152: retorno=51.99\n",
      "Episodio 153: retorno=38.38\n",
      " \n",
      "D:  1.182305097579956    Sigma:  0.22037314389716564\n",
      "Episodio 154: retorno=78.41\n",
      "Episodio 155: retorno=64.66\n",
      "Episodio 156: retorno=71.56\n",
      "Episodio 157: retorno=89.25\n",
      "Episodio 158: retorno=82.33\n",
      " \n",
      "D:  0.9820679426193237    Sigma:  0.21819123158135212\n",
      "Episodio 159: retorno=85.03\n",
      "Episodio 160: retorno=9.1\n",
      "Episodio 161: retorno=37.6\n",
      "Episodio 162: retorno=28.09\n",
      "Episodio 163: retorno=-6.57\n",
      " \n",
      "D:  1.498469352722168    Sigma:  0.21603092235777438\n",
      "Episodio 164: retorno=51.49\n",
      "Episodio 165: retorno=52.59\n",
      "Episodio 166: retorno=73.36\n",
      "Episodio 167: retorno=74.5\n",
      "Episodio 168: retorno=86.78\n",
      " \n",
      "D:  1.6400216817855835    Sigma:  0.21389200233443006\n",
      "Episodio 169: retorno=77.87\n",
      "Episodio 170: retorno=71.64\n",
      "Episodio 171: retorno=78.66\n",
      "Episodio 172: retorno=33.64\n",
      "Episodio 173: retorno=77.88\n",
      " \n",
      "D:  1.623716950416565    Sigma:  0.21177425973705946\n",
      "Episodio 174: retorno=5.18\n",
      "Episodio 175: retorno=17.95\n",
      "Episodio 176: retorno=33.56\n",
      "Episodio 177: retorno=86.13\n",
      "Episodio 178: retorno=75.09\n",
      " \n",
      "D:  2.026357412338257    Sigma:  0.2096774848881777\n",
      "Episodio 179: retorno=49.99\n",
      "Episodio 180: retorno=77.47\n",
      "Episodio 181: retorno=79.99\n",
      "Episodio 182: retorno=29.48\n",
      "Episodio 183: retorno=37.34\n",
      " \n",
      "D:  1.9371249675750732    Sigma:  0.20760147018631456\n",
      "Episodio 184: retorno=63.07\n",
      "Episodio 185: retorno=27.2\n",
      "Episodio 186: retorno=92.42\n",
      "Episodio 187: retorno=65.71\n",
      "Episodio 188: retorno=47.48\n",
      " \n",
      "D:  1.5506595373153687    Sigma:  0.20554601008545995\n",
      "Episodio 189: retorno=72.22\n",
      "Episodio 190: retorno=77.57\n",
      "Episodio 191: retorno=78.84\n",
      "Episodio 192: retorno=70.06\n",
      "Episodio 193: retorno=80.2\n",
      " \n",
      "D:  2.5227644443511963    Sigma:  0.2035109010747128\n",
      "Episodio 194: retorno=77.85\n",
      "Episodio 195: retorno=70.68\n",
      "Episodio 196: retorno=34.99\n",
      "Episodio 197: retorno=41.35\n",
      "Episodio 198: retorno=39.24\n",
      " \n",
      "D:  1.8813315629959106    Sigma:  0.2014959416581315\n",
      "Episodio 199: retorno=80.04\n",
      "Episodio 200: retorno=30.43\n",
      "Episodio 201: retorno=32.03\n",
      "Episodio 202: retorno=78.14\n",
      "Episodio 203: retorno=80.28\n",
      " \n",
      "D:  2.402111768722534    Sigma:  0.19950093233478366\n",
      "Episodio 204: retorno=23.1\n",
      "Episodio 205: retorno=79.07\n",
      "Episodio 206: retorno=72.0\n",
      "Episodio 207: retorno=50.94\n",
      "Episodio 208: retorno=9.76\n",
      " \n",
      "D:  2.063434362411499    Sigma:  0.19752567557899373\n",
      "Episodio 209: retorno=79.75\n",
      "Episodio 210: retorno=82.2\n",
      "Episodio 211: retorno=70.25\n",
      "Episodio 212: retorno=40.27\n",
      "Episodio 213: retorno=51.84\n",
      " \n",
      "D:  1.497210144996643    Sigma:  0.19556997582078586\n",
      "Episodio 214: retorno=78.37\n",
      "Episodio 215: retorno=91.21\n",
      "Episodio 216: retorno=81.11\n",
      "Episodio 217: retorno=76.06\n",
      "Episodio 218: retorno=34.05\n",
      " \n",
      "D:  1.5384641885757446    Sigma:  0.19363363942652065\n",
      "Episodio 219: retorno=80.22\n",
      "Episodio 220: retorno=12.89\n",
      "Episodio 221: retorno=39.51\n",
      "Episodio 222: retorno=29.65\n",
      "Episodio 223: retorno=33.52\n",
      " \n",
      "D:  1.7664183378219604    Sigma:  0.19171647467972341\n",
      "Episodio 224: retorno=80.13\n",
      "Episodio 225: retorno=76.71\n",
      "Episodio 226: retorno=85.39\n",
      "Episodio 227: retorno=78.8\n",
      "Episodio 228: retorno=49.56\n",
      " \n",
      "D:  1.5818017721176147    Sigma:  0.18981829176210238\n",
      "Episodio 229: retorno=35.59\n",
      "Episodio 230: retorno=63.27\n",
      "Episodio 231: retorno=30.88\n",
      "Episodio 232: retorno=78.35\n",
      "Episodio 233: retorno=79.04\n",
      " \n",
      "D:  1.3943068981170654    Sigma:  0.18793890273475483\n",
      "Episodio 234: retorno=76.09\n",
      "Episodio 235: retorno=85.61\n",
      "Episodio 236: retorno=79.66\n",
      "Episodio 237: retorno=27.42\n",
      "Episodio 238: retorno=73.34\n",
      " \n",
      "D:  2.339237928390503    Sigma:  0.18607812151955924\n",
      "Episodio 239: retorno=78.72\n",
      "Episodio 240: retorno=65.47\n",
      "Episodio 241: retorno=84.68\n",
      "Episodio 242: retorno=78.72\n",
      "Episodio 243: retorno=37.01\n",
      " \n",
      "D:  2.072266101837158    Sigma:  0.18423576388075172\n",
      "Episodio 244: retorno=22.89\n",
      "Episodio 245: retorno=79.54\n",
      "Episodio 246: retorno=78.84\n",
      "Episodio 247: retorno=15.82\n",
      "Episodio 248: retorno=72.71\n",
      " \n",
      "D:  2.438235282897949    Sigma:  0.18241164740668486\n",
      "Episodio 249: retorno=89.06\n",
      "Episodio 250: retorno=79.35\n",
      "Episodio 251: retorno=73.93\n",
      "Episodio 252: retorno=9.25\n",
      "Episodio 253: retorno=73.92\n",
      " \n",
      "D:  2.295313596725464    Sigma:  0.1806055914917672\n",
      "Episodio 254: retorno=33.11\n",
      "Episodio 255: retorno=85.84\n",
      "Episodio 256: retorno=36.69\n",
      "Episodio 257: retorno=70.13\n",
      "Episodio 258: retorno=57.87\n",
      " \n",
      "D:  1.2655531167984009    Sigma:  0.1788174173185814\n",
      "Episodio 259: retorno=84.78\n",
      "Episodio 260: retorno=14.64\n",
      "Episodio 261: retorno=85.29\n",
      "Episodio 262: retorno=70.28\n",
      "Episodio 263: retorno=9.01\n",
      " \n",
      "D:  1.8965997695922852    Sigma:  0.1770469478401796\n",
      "Episodio 264: retorno=72.08\n",
      "Episodio 265: retorno=17.73\n",
      "Episodio 266: retorno=65.36\n",
      "Episodio 267: retorno=28.69\n",
      "Episodio 268: retorno=51.28\n",
      " \n",
      "D:  1.2412502765655518    Sigma:  0.17529400776255405\n",
      "Episodio 269: retorno=49.69\n",
      "Episodio 270: retorno=40.98\n",
      "Episodio 271: retorno=79.14\n",
      "Episodio 272: retorno=32.01\n",
      "Episodio 273: retorno=47.93\n",
      " \n",
      "D:  0.6556009650230408    Sigma:  0.17355842352728124\n",
      "Episodio 274: retorno=80.72\n",
      "Episodio 275: retorno=78.09\n",
      "Episodio 276: retorno=58.73\n",
      "Episodio 277: retorno=70.19\n",
      "Episodio 278: retorno=49.1\n",
      " \n",
      "D:  0.8840186595916748    Sigma:  0.17184002329433787\n",
      "Episodio 279: retorno=78.95\n",
      "Episodio 280: retorno=73.45\n",
      "Episodio 281: retorno=69.98\n",
      "Episodio 282: retorno=70.71\n",
      "Episodio 283: retorno=34.43\n",
      " \n",
      "D:  1.0157098770141602    Sigma:  0.170138636925087\n",
      "Episodio 284: retorno=86.86\n",
      "Episodio 285: retorno=42.01\n",
      "Episodio 286: retorno=72.78\n",
      "Episodio 287: retorno=15.2\n",
      "Episodio 288: retorno=83.45\n",
      " \n",
      "D:  1.228495717048645    Sigma:  0.16845409596543265\n",
      "Episodio 289: retorno=70.31\n",
      "Episodio 290: retorno=74.5\n",
      "Episodio 291: retorno=63.2\n",
      "Episodio 292: retorno=70.25\n",
      "Episodio 293: retorno=78.09\n",
      " \n",
      "D:  0.9882957935333252    Sigma:  0.16678623362914125\n",
      "Episodio 294: retorno=79.13\n",
      "Episodio 295: retorno=47.0\n",
      "Episodio 296: retorno=52.0\n",
      "Episodio 297: retorno=33.33\n",
      "Episodio 298: retorno=65.81\n",
      " \n",
      "D:  0.8953562378883362    Sigma:  0.16513488478132796\n",
      "Episodio 299: retorno=77.68\n",
      "Episodio 300: retorno=65.88\n",
      "Episodio 301: retorno=51.72\n",
      "Episodio 302: retorno=81.44\n",
      "Episodio 303: retorno=50.34\n",
      " \n",
      "D:  0.5259485244750977    Sigma:  0.16349988592210687\n",
      "Episodio 304: retorno=76.47\n",
      "Episodio 305: retorno=47.8\n",
      "Episodio 306: retorno=83.19\n",
      "Episodio 307: retorno=71.54\n",
      "Episodio 308: retorno=88.75\n",
      " \n",
      "D:  0.33139827847480774    Sigma:  0.16188107517040284\n",
      "Episodio 309: retorno=79.11\n",
      "Episodio 310: retorno=70.91\n",
      "Episodio 311: retorno=71.14\n",
      "Episodio 312: retorno=77.97\n",
      "Episodio 313: retorno=80.66\n",
      " \n",
      "D:  0.29699116945266724    Sigma:  0.16027829224792361\n",
      "Episodio 314: retorno=78.77\n",
      "Episodio 315: retorno=76.28\n",
      "Episodio 316: retorno=78.11\n",
      "Episodio 317: retorno=12.8\n",
      "Episodio 318: retorno=71.5\n",
      " \n",
      "D:  0.6037940979003906    Sigma:  0.1586913784632907\n",
      "Episodio 319: retorno=75.99\n",
      "Episodio 320: retorno=50.47\n",
      "Episodio 321: retorno=83.24\n",
      "Episodio 322: retorno=20.43\n",
      "Episodio 323: retorno=65.16\n",
      " \n",
      "D:  0.5866267681121826    Sigma:  0.15712017669632744\n",
      "Episodio 324: retorno=57.02\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 1000\n",
    "list_retorno = []\n",
    "param_noise, ac_noise = True, None\n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and state\n",
    "    state = env.reset()\n",
    "    retorno = 0\n",
    "    steps=0\n",
    "    for t in count():\n",
    "        #env.render()\n",
    "        # Select and perform an action\n",
    "        action = select_action(torch.FloatTensor([state]).to(device), ac_noise, param_noise).cpu()\n",
    "        next_state, reward, done, _ = env.step([action])\n",
    "        reward = (reward + 8)/8\n",
    "        retorno += reward\n",
    "\n",
    "        # Store the transition in memory\n",
    "        memory.push(torch.FloatTensor([state]),\n",
    "                     action.to(device),  # action is already a tensor\n",
    "                     torch.FloatTensor([next_state]),\n",
    "                     torch.FloatTensor([reward]).to(device))\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "        steps += 1\n",
    "\n",
    "        # Perform one step of the optimization (on the policy network)\n",
    "        if optimize_model(t) != None:\n",
    "            state_batch, action_batch = optimize_model(t)\n",
    "        if done:\n",
    "            break\n",
    "    \n",
    "    if ac_noise == True:\n",
    "        if (i_episode+1) % T_adapt_ac == 0: \n",
    "            desv_pad_ac = desv_pad_ac/alfa_ac\n",
    "            print('\\n Sigma: ', desv_pad_ac)\n",
    "    if param_noise == True:\n",
    "        if (i_episode+1) % T_adapt == 0: \n",
    "            unpertubed_action = select_action(state_batch)\n",
    "            perturbed_actions = action_batch\n",
    "            \n",
    "            d = loss_d(unpertubed_action, perturbed_actions)\n",
    "            d = torch.mean(d)\n",
    "            if d <= delta:\n",
    "                sigma_0 = sigma_0*alfa\n",
    "            else:\n",
    "                sigma_0 = sigma_0/alfa\n",
    "            print(\" \\nD: \", d.item(), '   Sigma: ', sigma_0)\n",
    "        \n",
    "    print(f'Episodio {i_episode}: retorno={round(retorno,2)}')\n",
    "    list_retorno.append(retorno)\n",
    "\n",
    "print('Complete')\n",
    "env.render()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.code.notebook.error": {
       "message": "atob is not defined",
       "name": "ReferenceError",
       "stack": "ReferenceError: atob is not defined\n\tat d (/snap/code-insiders/772/usr/share/code-insiders/resources/app/extensions/ipynb/dist/ipynbMain.js:1:138755)\n\tat y (/snap/code-insiders/772/usr/share/code-insiders/resources/app/extensions/ipynb/dist/ipynbMain.js:1:143435)\n\tat v (/snap/code-insiders/772/usr/share/code-insiders/resources/app/extensions/ipynb/dist/ipynbMain.js:1:143731)\n\tat Array.map (<anonymous>)\n\tat /snap/code-insiders/772/usr/share/code-insiders/resources/app/extensions/ipynb/dist/ipynbMain.js:1:144883\n\tat /snap/code-insiders/772/usr/share/code-insiders/resources/app/extensions/ipynb/dist/ipynbMain.js:1:145125\n\tat /snap/code-insiders/772/usr/share/code-insiders/resources/app/extensions/ipynb/dist/ipynbMain.js:1:145132\n\tat Array.map (<anonymous>)\n\tat e.jupyterNotebookModelToNotebookData (/snap/code-insiders/772/usr/share/code-insiders/resources/app/extensions/ipynb/dist/ipynbMain.js:1:144441)\n\tat e.NotebookSerializer.deserializeNotebook (/snap/code-insiders/772/usr/share/code-insiders/resources/app/extensions/ipynb/dist/ipynbMain.js:1:146368)\n\tat _.$dataToNotebook (/snap/code-insiders/772/usr/share/code-insiders/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:85:211883)\n\tat d._doInvokeHandler (/snap/code-insiders/772/usr/share/code-insiders/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:89:12819)\n\tat d._invokeHandler (/snap/code-insiders/772/usr/share/code-insiders/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:89:12503)\n\tat d._receiveRequest (/snap/code-insiders/772/usr/share/code-insiders/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:89:11107)\n\tat d._receiveOneMessage (/snap/code-insiders/772/usr/share/code-insiders/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:89:10142)\n\tat /snap/code-insiders/772/usr/share/code-insiders/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:89:8039\n\tat u.fire (/snap/code-insiders/772/usr/share/code-insiders/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:57:1712)\n\tat l.fire (/snap/code-insiders/772/usr/share/code-insiders/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:65:15825)\n\tat /snap/code-insiders/772/usr/share/code-insiders/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:104:30061\n\tat u.fire (/snap/code-insiders/772/usr/share/code-insiders/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:57:1712)\n\tat l.fire (/snap/code-insiders/772/usr/share/code-insiders/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:65:15825)\n\tat r._receiveMessage (/snap/code-insiders/772/usr/share/code-insiders/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:65:21091)\n\tat /snap/code-insiders/772/usr/share/code-insiders/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:65:17969\n\tat u.fire (/snap/code-insiders/772/usr/share/code-insiders/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:57:1712)\n\tat v.acceptChunk (/snap/code-insiders/772/usr/share/code-insiders/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:65:13186)\n\tat /snap/code-insiders/772/usr/share/code-insiders/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:65:12534\n\tat Socket.w (/snap/code-insiders/772/usr/share/code-insiders/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:104:13219)\n\tat Socket.emit (events.js:315:20)\n\tat addChunk (internal/streams/readable.js:309:12)\n\tat readableAddChunk (internal/streams/readable.js:284:9)\n\tat Socket.Readable.push (internal/streams/readable.js:223:10)\n\tat Pipe.onStreamRead (internal/stream_base_commons.js:188:23)"
      },
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list_retorno)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9ce0952ff6b7703ad76d22f6fe0d43fce5ecd4387907aaa0af2410b7aa492de3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
